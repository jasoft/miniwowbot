"""
OCR Helper Class - åŸºäºPaddleOCRçš„æ–‡å­—è¯†åˆ«å’Œå®šä½å·¥å…·ç±»
æä¾›ç»Ÿä¸€çš„æ¥å£ä¾›å¤–éƒ¨è°ƒç”¨ï¼Œè¾“å…¥å›¾åƒæ–‡ä»¶å’Œè¦æŸ¥æ‰¾çš„æ–‡å­—ï¼Œè¿”å›æ–‡å­—æ‰€åœ¨çš„å›¾ç‰‡åŒºåŸŸ
"""

from paddleocr import PaddleOCR
import json
import os
import time
import cv2
from airtest.core.api import *
from airtest.aircv.cal_confidence import cal_ccoeff_confidence
import logging
import coloredlogs


class OCRHelper:
    """OCRè¾…åŠ©å·¥å…·ç±»ï¼Œå°è£…PaddleOCRåŠŸèƒ½"""

    def __init__(
        self,
        output_dir="output",
        use_doc_orientation_classify=False,
        use_doc_unwarping=False,
        use_textline_orientation=False,
    ):
        """
        åˆå§‹åŒ–OCR Helper

        Args:
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
            use_doc_orientation_classify (bool): æ˜¯å¦ä½¿ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»æ¨¡å‹
            use_doc_unwarping (bool): æ˜¯å¦ä½¿ç”¨æ–‡æœ¬å›¾åƒçŸ«æ­£æ¨¡å‹
            use_textline_orientation (bool): æ˜¯å¦ä½¿ç”¨æ–‡æœ¬è¡Œæ–¹å‘åˆ†ç±»æ¨¡å‹
        """
        self.output_dir = output_dir
        self.ocr = PaddleOCR(
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False,
            text_detection_model_name="PP-OCRv5_mobile_det",
            text_recognition_model_name="PP-OCRv5_mobile_rec",
            lang="ch",
            cpu_threads=16,
        )

        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        # é…ç½®å½©è‰²æ—¥å¿—ï¼ˆéœ€è¦å…ˆåˆå§‹åŒ–ï¼Œå› ä¸ºç¼“å­˜åŠ è½½æ—¶ä¼šç”¨åˆ°ï¼‰
        self.logger = logging.getLogger(f"{__name__}.OCRHelper")
        # é˜²æ­¢æ—¥å¿—é‡å¤ï¼šç§»é™¤å·²æœ‰çš„ handlers
        self.logger.handlers.clear()
        self.logger.propagate = False

        coloredlogs.install(
            level="DEBUG",
            logger=self.logger,
            fmt="%(asctime)s %(name)s %(levelname)s %(message)s",
            datefmt="%H:%M:%S",
            level_styles={
                "debug": {"color": "cyan"},
                "info": {"color": "blue"},
                "warning": {"color": "yellow"},
                "error": {"color": "red"},
                "critical": {"color": "red", "bold": True},
            },
        )

        # åˆå§‹åŒ–ç¼“å­˜
        # æ ¼å¼: [(image_path, json_file_path), ...]
        self.ocr_cache = []
        self.cache_dir = os.path.join(self.output_dir, "cache")
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)

        # ç¼“å­˜ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ95%ä»¥ä¸Šè®¤ä¸ºæ˜¯åŒä¸€å¼ å›¾ï¼‰
        self.cache_similarity_threshold = 0.95

        # åŠ è½½å·²æœ‰çš„ç¼“å­˜ï¼ˆéœ€è¦åœ¨ logger åˆå§‹åŒ–ä¹‹åï¼‰
        self._load_existing_cache()

    def _load_existing_cache(self):
        """
        åŠ è½½ç¼“å­˜ç›®å½•ä¸­å·²æœ‰çš„ç¼“å­˜æ–‡ä»¶
        """
        try:
            if not os.path.exists(self.cache_dir):
                return

            # æŸ¥æ‰¾æ‰€æœ‰ç¼“å­˜æ–‡ä»¶å¯¹
            cache_files = os.listdir(self.cache_dir)
            cache_pairs = {}

            # å°†å›¾ç‰‡å’Œ JSON æ–‡ä»¶é…å¯¹
            for filename in cache_files:
                if filename.startswith("cache_") and filename.endswith(".png"):
                    # æå–ç¼“å­˜ ID
                    cache_id = filename.replace("cache_", "").replace(".png", "")
                    json_filename = f"cache_{cache_id}_res.json"

                    image_path = os.path.join(self.cache_dir, filename)
                    json_path = os.path.join(self.cache_dir, json_filename)

                    # æ£€æŸ¥å¯¹åº”çš„ JSON æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if os.path.exists(json_path):
                        cache_pairs[cache_id] = (image_path, json_path)

            # æŒ‰ ID æ’åºå¹¶åŠ è½½åˆ°ç¼“å­˜åˆ—è¡¨
            for cache_id in sorted(
                cache_pairs.keys(), key=lambda x: int(x) if x.isdigit() else 0
            ):
                self.ocr_cache.append(cache_pairs[cache_id])

            if self.ocr_cache:
                self.logger.info(f"ğŸ’¾ åŠ è½½äº† {len(self.ocr_cache)} ä¸ªç¼“å­˜æ–‡ä»¶")
        except Exception as e:
            self.logger.error(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")

    def _find_similar_cached_image(self, current_image_path):
        """
        æŸ¥æ‰¾ç¼“å­˜ä¸­æ˜¯å¦æœ‰ç›¸ä¼¼çš„å›¾ç‰‡

        Args:
            current_image_path (str): å½“å‰å›¾ç‰‡è·¯å¾„

        Returns:
            str: ç¼“å­˜çš„ JSON æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å› None
        """
        try:
            current_img = cv2.imread(current_image_path)
            if current_img is None:
                return None

            # éå†ç¼“å­˜ï¼ŒæŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡
            for cached_img_path, cached_json_path in self.ocr_cache:
                if not os.path.exists(cached_img_path) or not os.path.exists(
                    cached_json_path
                ):
                    continue

                cached_img = cv2.imread(cached_img_path)
                if cached_img is None:
                    continue

                # è°ƒæ•´å›¾ç‰‡å°ºå¯¸ä¸€è‡´ä»¥ä¾¿æ¯”è¾ƒ
                if current_img.shape != cached_img.shape:
                    cached_img = cv2.resize(
                        cached_img, (current_img.shape[1], current_img.shape[0])
                    )

                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = cal_ccoeff_confidence(current_img, cached_img)

                if similarity >= self.cache_similarity_threshold:
                    self.logger.info(
                        f"ğŸ’¾ æ‰¾åˆ°ç›¸ä¼¼ç¼“å­˜å›¾ç‰‡ (ç›¸ä¼¼åº¦: {similarity * 100:.1f}%)"
                    )
                    return cached_json_path

            return None
        except Exception as e:
            self.logger.error(f"æŸ¥æ‰¾ç›¸ä¼¼ç¼“å­˜å›¾ç‰‡å¤±è´¥: {e}")
            return None

    def _save_to_cache(self, image_path, json_file):
        """
        ä¿å­˜å›¾ç‰‡å’Œ OCR ç»“æœåˆ°ç¼“å­˜

        Args:
            image_path (str): å›¾ç‰‡è·¯å¾„
            json_file (str): JSON æ–‡ä»¶è·¯å¾„
        """
        try:
            import shutil

            # ä¸ºç¼“å­˜åˆ›å»ºå”¯ä¸€çš„æ–‡ä»¶å
            cache_id = len(self.ocr_cache)
            cache_image_name = f"cache_{cache_id}.png"
            cache_json_name = f"cache_{cache_id}_res.json"

            cache_image_path = os.path.join(self.cache_dir, cache_image_name)
            cache_json_path = os.path.join(self.cache_dir, cache_json_name)

            # å¤åˆ¶å›¾ç‰‡åˆ°ç¼“å­˜ç›®å½•
            shutil.copy2(image_path, cache_image_path)

            # å¤åˆ¶ JSON åˆ°ç¼“å­˜ç›®å½•
            if os.path.exists(json_file):
                shutil.copy2(json_file, cache_json_path)
                # ä¿å­˜ç¼“å­˜è®°å½•
                self.ocr_cache.append((cache_image_path, cache_json_path))
                self.logger.debug(
                    f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜ (å›¾ç‰‡æ•°: {len(self.ocr_cache)}, JSON: {cache_json_name})"
                )
            else:
                self.logger.error(f"JSON æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ç¼“å­˜: {json_file}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _predict_with_timing(self, image_path):
        """
        æ‰§è¡Œ OCR è¯†åˆ«å¹¶è®°å½•è€—æ—¶

        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„

        Returns:
            OCR è¯†åˆ«ç»“æœ
        """
        start_time = time.time()
        result = self.ocr.predict(image_path)
        elapsed_time = time.time() - start_time

        filename = os.path.basename(image_path)
        self.logger.info(f"â±ï¸ OCRè¯†åˆ«è€—æ—¶: {elapsed_time:.3f}ç§’ (æ–‡ä»¶: {filename})")

        return result

    def _get_or_create_ocr_result(self, image_path, use_cache=True):
        """
        è·å–æˆ–åˆ›å»º OCR è¯†åˆ«ç»“æœï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
            use_cache (bool): æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤ä¸º True

        Returns:
            str: JSON æ–‡ä»¶è·¯å¾„
        """
        # å¦‚æœå¯ç”¨ç¼“å­˜ï¼Œæ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰ç›¸ä¼¼å›¾ç‰‡
        if use_cache:
            cached_json = self._find_similar_cached_image(image_path)
            if cached_json:
                return cached_json

        # ç¼“å­˜æœªå‘½ä¸­æˆ–ç¦ç”¨ç¼“å­˜ï¼Œæ‰§è¡Œ OCR è¯†åˆ«
        result = self._predict_with_timing(image_path)

        if result and len(result) > 0:
            # å…ˆä¿å­˜åˆ° output ç›®å½•ï¼ˆæ ‡å‡†æµç¨‹ï¼‰
            for res in result:
                res.save_to_json(self.output_dir)

            # è·å– JSON æ–‡ä»¶è·¯å¾„
            json_file = os.path.join(
                self.output_dir,
                os.path.basename(image_path).replace(".png", "_res.json"),
            )

            # å¦‚æœå¯ç”¨ç¼“å­˜ï¼ŒåŒæ—¶ä¿å­˜åˆ°ç¼“å­˜
            if use_cache and os.path.exists(json_file):
                self._save_to_cache(image_path, json_file)

            return json_file

        return None

    def find_text_in_image(
        self,
        image_path,
        target_text,
        confidence_threshold=0.5,
        occurrence=1,
        use_cache=True,
    ):
        """
        åœ¨æŒ‡å®šå›¾åƒä¸­æŸ¥æ‰¾ç›®æ ‡æ–‡å­—çš„ä½ç½®

        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
            target_text (str): è¦æŸ¥æ‰¾çš„ç›®æ ‡æ–‡å­—
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)
            occurrence (int): æŒ‡å®šç‚¹å‡»ç¬¬å‡ ä¸ªå‡ºç°çš„æ–‡å­— (1-based)ï¼Œé»˜è®¤ä¸º1
            use_cache (bool): æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤ä¸º True

        Returns:
            dict: åŒ…å«ä»¥ä¸‹ä¿¡æ¯çš„å­—å…¸
                - found (bool): æ˜¯å¦æ‰¾åˆ°æ–‡å­—
                - center (tuple): æ–‡å­—ä¸­å¿ƒåæ ‡ (x, y)ï¼Œæœªæ‰¾åˆ°æ—¶ä¸ºNone
                - text (str): å®é™…è¯†åˆ«åˆ°çš„æ–‡å­—ï¼Œæœªæ‰¾åˆ°æ—¶ä¸ºNone
                - confidence (float): ç½®ä¿¡åº¦ï¼Œæœªæ‰¾åˆ°æ—¶ä¸ºNone
                - bbox (list): æ–‡å­—è¾¹ç•Œæ¡†åæ ‡ï¼Œæœªæ‰¾åˆ°æ—¶ä¸ºNone
                - total_matches (int): æ€»å…±æ‰¾åˆ°çš„åŒ¹é…æ•°é‡
                - selected_index (int): å®é™…é€‰æ‹©çš„ç´¢å¼• (1-based)
        """
        try:
            # è·å–æˆ–åˆ›å»º OCR ç»“æœï¼ˆå¸¦ç¼“å­˜ï¼‰
            json_file = self._get_or_create_ocr_result(image_path, use_cache=use_cache)

            if not json_file:
                self.logger.warning(f"OCRè¯†åˆ«ç»“æœä¸ºç©º: {image_path}")
                return {
                    "found": False,
                    "center": None,
                    "text": None,
                    "confidence": None,
                    "bbox": None,
                    "total_matches": 0,
                    "selected_index": 0,
                }

            # ä» JSON ä¸­æŸ¥æ‰¾ç›®æ ‡æ–‡å­—
            return self._find_text_in_json(
                json_file, target_text, confidence_threshold, occurrence
            )

        except Exception as e:
            self.logger.error(f"å›¾åƒOCRè¯†åˆ«å‡ºé”™: {e}")
            return {
                "found": False,
                "center": None,
                "text": None,
                "confidence": None,
                "bbox": None,
                "total_matches": 0,
                "selected_index": 0,
            }

    def capture_and_find_text(
        self,
        target_text,
        confidence_threshold=0.5,
        screenshot_path="/tmp/screenshot.png",
        occurrence=1,
        use_cache=True,
    ):
        """
        æˆªå›¾å¹¶æŸ¥æ‰¾ç›®æ ‡æ–‡å­—çš„ä½ç½®

        Args:
            target_text (str): è¦æŸ¥æ‰¾çš„ç›®æ ‡æ–‡å­—
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)
            screenshot_path (str): æˆªå›¾ä¿å­˜è·¯å¾„
            occurrence (int): æŒ‡å®šç‚¹å‡»ç¬¬å‡ ä¸ªå‡ºç°çš„æ–‡å­— (1-based)ï¼Œé»˜è®¤ä¸º1
            use_cache (bool): æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤ä¸º True

        Returns:
            dict: åŒ…å«æŸ¥æ‰¾ç»“æœçš„å­—å…¸ï¼Œæ ¼å¼åŒfind_text_in_image
        """
        try:
            # æˆªå›¾
            snapshot(filename=screenshot_path)
            self.logger.info(f"æˆªå›¾ä¿å­˜åˆ°: {screenshot_path}")

            # åœ¨æˆªå›¾ä¸­æŸ¥æ‰¾æ–‡å­—
            return self.find_text_in_image(
                screenshot_path,
                target_text,
                confidence_threshold,
                occurrence,
                use_cache,
            )

        except Exception as e:
            self.logger.error(f"æˆªå›¾å’Œè¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}")
            return {
                "found": False,
                "center": None,
                "text": None,
                "confidence": None,
                "bbox": None,
                "total_matches": 0,
                "selected_index": 0,
            }

    def find_and_click_text(
        self,
        target_text,
        confidence_threshold=0.5,
        screenshot_path="/tmp/screenshot.png",
        occurrence=1,
        use_cache=True,
    ):
        """
        æˆªå›¾ã€æŸ¥æ‰¾æ–‡å­—å¹¶ç‚¹å‡»å…¶ä¸­å¿ƒç‚¹

        Args:
            target_text (str): è¦æŸ¥æ‰¾çš„ç›®æ ‡æ–‡å­—
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)
            screenshot_path (str): æˆªå›¾ä¿å­˜è·¯å¾„
            occurrence (int): æŒ‡å®šç‚¹å‡»ç¬¬å‡ ä¸ªå‡ºç°çš„æ–‡å­— (1-based)ï¼Œé»˜è®¤ä¸º1
            use_cache (bool): æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤ä¸º True

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ‰¾åˆ°å¹¶ç‚¹å‡»
        """
        result = self.capture_and_find_text(
            target_text, confidence_threshold, screenshot_path, occurrence, use_cache
        )

        if result["found"]:
            center = result["center"]
            self.logger.info(f"ç‚¹å‡»ä½ç½®: {center}")
            touch(center)
            return True
        else:
            self.logger.warning(f"æ— æ³•ç‚¹å‡»ï¼Œæœªæ‰¾åˆ°æ–‡å­—: '{target_text}'")
            return False

    def _find_text_in_json(
        self, json_file_path, target_text, confidence_threshold=0.5, occurrence=1
    ):
        """
        ä»PaddleOCRè¾“å‡ºçš„JSONæ–‡ä»¶ä¸­æŸ¥æ‰¾ç›®æ ‡æ–‡å­—

        Args:
            json_file_path (str): JSONæ–‡ä»¶è·¯å¾„
            target_text (str): è¦æŸ¥æ‰¾çš„ç›®æ ‡æ–‡å­—
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)
            occurrence (int): æŒ‡å®šè¿”å›ç¬¬å‡ ä¸ªå‡ºç°çš„æ–‡å­— (1-based)ï¼Œé»˜è®¤ä¸º1

        Returns:
            dict: æŸ¥æ‰¾ç»“æœå­—å…¸
        """
        try:
            # è¯»å–JSONæ–‡ä»¶
            with open(json_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            # è·å–è¯†åˆ«çš„æ–‡å­—åˆ—è¡¨å’Œå¯¹åº”çš„åæ ‡æ¡†
            rec_texts = data.get("rec_texts", [])
            rec_scores = data.get("rec_scores", [])
            dt_polys = data.get("dt_polys", [])  # æ£€æµ‹æ¡†åæ ‡

            self.logger.info(f"åœ¨JSONä¸­æŸ¥æ‰¾æ–‡å­—: '{target_text}' (ç¬¬{occurrence}ä¸ª)")
            self.logger.info(f"æ€»å…±è¯†åˆ«åˆ° {len(rec_texts)} ä¸ªæ–‡å­—")

            # æ”¶é›†æ‰€æœ‰åŒ¹é…çš„æ–‡å­—
            matches = []
            for i, (text, score) in enumerate(zip(rec_texts, rec_scores)):
                self.logger.debug(f"  {i + 1:2d}. '{text}' (ç½®ä¿¡åº¦: {score:.3f})")

                # æ£€æŸ¥ç½®ä¿¡åº¦å’Œæ–‡å­—åŒ¹é…ï¼ˆè¯†åˆ«å‡ºçš„æ–‡å­—åŒ…å«ç›®æ ‡æ–‡å­—ï¼‰
                if score >= confidence_threshold and target_text in text:
                    # è·å–å¯¹åº”çš„åæ ‡æ¡†
                    if i < len(dt_polys):
                        poly = dt_polys[i]

                        # è®¡ç®—ä¸­å¿ƒç‚¹åæ ‡
                        # poly æ ¼å¼: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                        x_coords = [point[0] for point in poly]
                        y_coords = [point[1] for point in poly]
                        center_x = int(sum(x_coords) / len(x_coords))
                        center_y = int(sum(y_coords) / len(y_coords))

                        matches.append(
                            {
                                "center": (center_x, center_y),
                                "text": text,
                                "confidence": score,
                                "bbox": poly,
                                "index": len(matches) + 1,
                            }
                        )

            total_matches = len(matches)
            self.logger.info(f"æ‰¾åˆ° {total_matches} ä¸ªåŒ¹é…çš„æ–‡å­—")

            if total_matches == 0:
                self.logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡å­—: '{target_text}'")
                return {
                    "found": False,
                    "center": None,
                    "text": None,
                    "confidence": None,
                    "bbox": None,
                    "total_matches": 0,
                    "selected_index": 0,
                }

            # æ˜¾ç¤ºæ‰€æœ‰åŒ¹é…çš„æ–‡å­—
            for i, match in enumerate(matches, 1):
                self.logger.info(
                    f"  åŒ¹é… {i}: '{match['text']}' (ç½®ä¿¡åº¦: {match['confidence']:.3f}) ä½ç½®: {match['center']}"
                )

            # é€‰æ‹©æŒ‡å®šçš„åŒ¹é…é¡¹
            if occurrence > total_matches:
                self.logger.warning(
                    f"è¯·æ±‚ç¬¬{occurrence}ä¸ªåŒ¹é…ï¼Œä½†åªæ‰¾åˆ°{total_matches}ä¸ªï¼Œä½¿ç”¨æœ€åä¸€ä¸ª"
                )
                selected_match = matches[-1]
                selected_index = total_matches
            else:
                selected_match = matches[occurrence - 1]
                selected_index = occurrence

            self.logger.info(
                f"é€‰æ‹©ç¬¬{selected_index}ä¸ªåŒ¹é…: '{selected_match['text']}'"
            )
            self.logger.info(f"åæ ‡æ¡†: {selected_match['bbox']}")
            self.logger.info(f"ä¸­å¿ƒç‚¹: {selected_match['center']}")

            return {
                "found": True,
                "center": selected_match["center"],
                "text": selected_match["text"],
                "confidence": selected_match["confidence"],
                "bbox": selected_match["bbox"],
                "total_matches": total_matches,
                "selected_index": selected_index,
            }

        except FileNotFoundError:
            self.logger.error(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
            return {
                "found": False,
                "center": None,
                "text": None,
                "confidence": None,
                "bbox": None,
                "total_matches": 0,
                "selected_index": 0,
            }
        except json.JSONDecodeError:
            self.logger.error(f"JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {json_file_path}")
            return {
                "found": False,
                "center": None,
                "text": None,
                "confidence": None,
                "bbox": None,
                "total_matches": 0,
                "selected_index": 0,
            }
        except Exception as e:
            self.logger.error(f"å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return {
                "found": False,
                "center": None,
                "text": None,
                "confidence": None,
                "bbox": None,
                "total_matches": 0,
                "selected_index": 0,
            }

    def find_all_matching_texts(
        self, image_path, target_text, confidence_threshold=0.5
    ):
        """
        æŸ¥æ‰¾å›¾åƒä¸­æ‰€æœ‰åŒ¹é…çš„æ–‡å­—

        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
            target_text (str): è¦æŸ¥æ‰¾çš„ç›®æ ‡æ–‡å­—
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)

        Returns:
            list: åŒ…å«æ‰€æœ‰åŒ¹é…æ–‡å­—ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«center, text, confidence, bbox
        """
        try:
            # OCR è¯†åˆ«
            result = self._predict_with_timing(image_path)

            if not result or len(result) == 0:
                self.logger.warning(f"OCRè¯†åˆ«ç»“æœä¸ºç©º: {image_path}")
                return []

            # ä¿å­˜è¯†åˆ«ç»“æœåˆ°JSON
            for res in result:
                res.save_to_json(self.output_dir)

            # ä»ç»“æœä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡å­—
            json_file = os.path.join(
                self.output_dir,
                os.path.basename(image_path).replace(".png", "_res.json"),
            )
            return self._find_all_matching_texts_in_json(
                json_file, target_text, confidence_threshold
            )

        except Exception as e:
            self.logger.error(f"æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…æ–‡å­—æ—¶å‡ºé”™: {e}")
            return []

    def _find_all_matching_texts_in_json(
        self, json_file_path, target_text, confidence_threshold=0.5
    ):
        """
        ä»JSONæ–‡ä»¶ä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡å­—

        Args:
            json_file_path (str): JSONæ–‡ä»¶è·¯å¾„
            target_text (str): è¦æŸ¥æ‰¾çš„ç›®æ ‡æ–‡å­—
            confidence_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)

        Returns:
            list: æ‰€æœ‰åŒ¹é…çš„æ–‡å­—ä¿¡æ¯åˆ—è¡¨
        """
        try:
            with open(json_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            rec_texts = data.get("rec_texts", [])
            rec_scores = data.get("rec_scores", [])
            dt_polys = data.get("dt_polys", [])

            matches = []
            for i, (text, score) in enumerate(zip(rec_texts, rec_scores)):
                # æ£€æŸ¥ç½®ä¿¡åº¦å’Œæ–‡å­—åŒ¹é…ï¼ˆè¯†åˆ«å‡ºçš„æ–‡å­—åŒ…å«ç›®æ ‡æ–‡å­—ï¼‰
                if score >= confidence_threshold and target_text in text:
                    if i < len(dt_polys):
                        poly = dt_polys[i]
                        x_coords = [point[0] for point in poly]
                        y_coords = [point[1] for point in poly]
                        center_x = int(sum(x_coords) / len(x_coords))
                        center_y = int(sum(y_coords) / len(y_coords))

                        matches.append(
                            {
                                "center": (center_x, center_y),
                                "text": text,
                                "confidence": score,
                                "bbox": poly,
                                "index": len(matches) + 1,
                            }
                        )

            return matches

        except Exception as e:
            self.logger.error(f"å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return []

    def get_all_texts_from_image(self, image_path):
        """
        è·å–å›¾åƒä¸­æ‰€æœ‰è¯†åˆ«åˆ°çš„æ–‡å­—ä¿¡æ¯

        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„

        Returns:
            list: åŒ…å«æ‰€æœ‰æ–‡å­—ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—å…¸åŒ…å«text, confidence, center, bbox
        """
        try:
            # OCR è¯†åˆ«
            result = self._predict_with_timing(image_path)

            if not result or len(result) == 0:
                self.logger.warning(f"OCRè¯†åˆ«ç»“æœä¸ºç©º: {image_path}")
                return []

            # ä¿å­˜è¯†åˆ«ç»“æœåˆ°JSON
            for res in result:
                res.save_to_json(self.output_dir)

            # ä»JSONæ–‡ä»¶è¯»å–æ‰€æœ‰æ–‡å­—
            json_file = os.path.join(
                self.output_dir,
                os.path.basename(image_path).replace(".png", "_res.json"),
            )
            return self._get_all_texts_from_json(json_file)

        except Exception as e:
            self.logger.error(f"è·å–å›¾åƒæ–‡å­—ä¿¡æ¯å‡ºé”™: {e}")
            return []

    def _get_all_texts_from_json(self, json_file_path):
        """
        ä»JSONæ–‡ä»¶ä¸­è·å–æ‰€æœ‰æ–‡å­—ä¿¡æ¯

        Args:
            json_file_path (str): JSONæ–‡ä»¶è·¯å¾„

        Returns:
            list: æ‰€æœ‰æ–‡å­—ä¿¡æ¯åˆ—è¡¨
        """
        try:
            with open(json_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            rec_texts = data.get("rec_texts", [])
            rec_scores = data.get("rec_scores", [])
            dt_polys = data.get("dt_polys", [])

            texts_info = []

            for i, (text, score) in enumerate(zip(rec_texts, rec_scores)):
                if i < len(dt_polys):
                    poly = dt_polys[i]
                    x_coords = [point[0] for point in poly]
                    y_coords = [point[1] for point in poly]
                    center_x = int(sum(x_coords) / len(x_coords))
                    center_y = int(sum(y_coords) / len(y_coords))

                    texts_info.append(
                        {
                            "text": text,
                            "confidence": score,
                            "center": (center_x, center_y),
                            "bbox": poly,
                        }
                    )

            return texts_info

        except Exception as e:
            self.logger.error(f"è¯»å–JSONæ–‡ä»¶å‡ºé”™: {e}")
            return []
