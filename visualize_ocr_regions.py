#!/usr/bin/env python3
# -*- encoding=utf8 -*-
"""
OCR åŒºåŸŸå¯è§†åŒ–è„šæœ¬
è¯»å–å›¾ç‰‡ï¼Œè¯†åˆ«æ¯ä¸ªåŒºåŸŸçš„æ–‡å­—ï¼Œå¹¶ç”Ÿæˆæ ‡æ³¨å›¾ç‰‡
"""

import sys
import os
import cv2
import numpy as np

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ocr_helper import OCRHelper


def draw_text_boxes(image, ocr_results, region_id, color):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶æ–‡å­—è¾¹ç•Œæ¡†

    Args:
        image: OpenCV å›¾åƒ
        ocr_results: OCR è¯†åˆ«ç»“æœåˆ—è¡¨
        region_id: åŒºåŸŸç¼–å·
        color: è¾¹ç•Œæ¡†é¢œè‰² (B, G, R)
    """
    for res in ocr_results:
        try:
            # æ”¯æŒå­—å…¸è®¿é—®ï¼ˆOCRResult å¯¹è±¡ï¼‰
            rec_texts = res["rec_texts"]
            rec_scores = res["rec_scores"]
            dt_polys = res["dt_polys"]
        except (KeyError, TypeError):
            # å°è¯•å±æ€§è®¿é—®
            rec_texts = res.rec_texts if hasattr(res, "rec_texts") else []
            rec_scores = res.rec_scores if hasattr(res, "rec_scores") else []
            dt_polys = res.dt_polys if hasattr(res, "dt_polys") else []

        # ç»˜åˆ¶æ¯ä¸ªè¯†åˆ«åˆ°çš„æ–‡å­—
        for i, (text, score, bbox) in enumerate(zip(rec_texts, rec_scores, dt_polys)):
            if score < 0.5:  # è·³è¿‡ä½ç½®ä¿¡åº¦çš„ç»“æœ
                continue

            # è½¬æ¢ä¸ºæ•´æ•°åæ ‡
            points = np.array(bbox, dtype=np.int32)

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.polylines(image, [points], True, color, 2)

            # è®¡ç®—ä¸­å¿ƒç‚¹
            center_x = int((bbox[0][0] + bbox[2][0]) / 2)
            center_y = int((bbox[0][1] + bbox[2][1]) / 2)

            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(image, (center_x, center_y), 3, color, -1)

            # å‡†å¤‡æ ‡æ³¨æ–‡æœ¬
            label = f"{text} ({center_x},{center_y})"

            # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆåœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹ï¼‰
            text_x = int(bbox[0][0])
            text_y = int(bbox[0][1]) - 5

            # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
            (text_w, text_h), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            cv2.rectangle(
                image,
                (text_x, text_y - text_h - 2),
                (text_x + text_w, text_y + 2),
                color,
                -1,
            )

            # ç»˜åˆ¶æ–‡æœ¬
            cv2.putText(
                image,
                label,
                (text_x, text_y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )


def visualize_all_regions(image_path, output_path):
    """
    å¯è§†åŒ–æ‰€æœ‰åŒºåŸŸçš„ OCR è¯†åˆ«ç»“æœ

    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
    """
    # åˆ›å»º OCR Helper
    ocr = OCRHelper(output_dir="output")

    # è¯»å–å›¾åƒ
    if not os.path.exists(image_path):
        print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return

    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return

    height, width = image.shape[:2]
    print(f"âœ… å›¾åƒå°ºå¯¸: {width}x{height}")

    # åˆ›å»ºè¾“å‡ºå›¾åƒï¼ˆå¤åˆ¶åŸå›¾ï¼‰
    output_image = image.copy()

    # å®šä¹‰æ¯ä¸ªåŒºåŸŸçš„é¢œè‰²ï¼ˆBGR æ ¼å¼ï¼‰
    region_colors = {
        1: (255, 0, 0),  # è“è‰²
        2: (0, 255, 0),  # ç»¿è‰²
        3: (0, 0, 255),  # çº¢è‰²
        4: (255, 255, 0),  # é’è‰²
        5: (255, 0, 255),  # å“çº¢
        6: (0, 255, 255),  # é»„è‰²
        7: (128, 0, 128),  # ç´«è‰²
        8: (255, 128, 0),  # æ©™è‰²
        9: (0, 128, 255),  # å¤©è“è‰²
    }

    # ç»˜åˆ¶åŒºåŸŸåˆ†å‰²çº¿
    grid_color = (200, 200, 200)  # ç°è‰²

    # å‚ç›´åˆ†å‰²çº¿
    cv2.line(output_image, (width // 3, 0), (width // 3, height), grid_color, 1)
    cv2.line(output_image, (width * 2 // 3, 0), (width * 2 // 3, height), grid_color, 1)

    # æ°´å¹³åˆ†å‰²çº¿
    cv2.line(output_image, (0, height // 3), (width, height // 3), grid_color, 1)
    cv2.line(
        output_image, (0, height * 2 // 3), (width, height * 2 // 3), grid_color, 1
    )

    # æ ‡æ³¨åŒºåŸŸç¼–å·
    region_positions = [
        (width // 6, height // 6),  # åŒºåŸŸ 1
        (width // 2, height // 6),  # åŒºåŸŸ 2
        (width * 5 // 6, height // 6),  # åŒºåŸŸ 3
        (width // 6, height // 2),  # åŒºåŸŸ 4
        (width // 2, height // 2),  # åŒºåŸŸ 5
        (width * 5 // 6, height // 2),  # åŒºåŸŸ 6
        (width // 6, height * 5 // 6),  # åŒºåŸŸ 7
        (width // 2, height * 5 // 6),  # åŒºåŸŸ 8
        (width * 5 // 6, height * 5 // 6),  # åŒºåŸŸ 9
    ]

    for region_id in range(1, 10):
        pos = region_positions[region_id - 1]
        color = region_colors[region_id]

        # ç»˜åˆ¶åŒºåŸŸç¼–å·
        cv2.putText(
            output_image,
            f"R{region_id}",
            (pos[0] - 15, pos[1] - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            color,
            2,
        )

    # å¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡Œ OCR è¯†åˆ«
    print("\nğŸ” å¼€å§‹è¯†åˆ«å„ä¸ªåŒºåŸŸçš„æ–‡å­—...\n")

    total_texts = 0
    for region_id in range(1, 10):
        print(f"ğŸ“ åŒºåŸŸ {region_id}:")

        # æå–åŒºåŸŸ
        region_img, offset = ocr._extract_region(
            image,
            regions=[region_id],
            debug_save_path=f"/tmp/region_{region_id}_debug.png",
        )

        if region_img is None:
            print("   âŒ åŒºåŸŸæå–å¤±è´¥")
            continue

        # è¿›è¡Œ OCR è¯†åˆ«
        result = ocr.ocr.predict(region_img)

        if not result or len(result) == 0:
            print("   âš ï¸ æœªè¯†åˆ«åˆ°æ–‡å­—")
            continue

        # ç»Ÿè®¡è¯†åˆ«åˆ°çš„æ–‡å­—æ•°é‡
        text_count = 0
        for res in result:
            try:
                rec_texts = res["rec_texts"]
                text_count += len(rec_texts)
            except (KeyError, TypeError):
                rec_texts = res.rec_texts if hasattr(res, "rec_texts") else []
                text_count += len(rec_texts)

        print(f"   âœ… è¯†åˆ«åˆ° {text_count} ä¸ªæ–‡å­—")
        total_texts += text_count

        # è°ƒæ•´åæ ‡å¹¶ç»˜åˆ¶åˆ°è¾“å‡ºå›¾åƒ
        for res in result:
            try:
                rec_texts = res["rec_texts"]
                rec_scores = res["rec_scores"]
                dt_polys = res["dt_polys"]
            except (KeyError, TypeError):
                rec_texts = res.rec_texts if hasattr(res, "rec_texts") else []
                rec_scores = res.rec_scores if hasattr(res, "rec_scores") else []
                dt_polys = res.dt_polys if hasattr(res, "dt_polys") else []

            # è°ƒæ•´åæ ‡åˆ°åŸå›¾
            adjusted_polys = []
            for poly in dt_polys:
                adjusted_poly = [
                    [int(p[0] + offset[0]), int(p[1] + offset[1])] for p in poly
                ]
                adjusted_polys.append(adjusted_poly)

            # ç»˜åˆ¶æ–‡å­—è¾¹ç•Œæ¡†
            color = region_colors[region_id]
            for i, (text, score, bbox) in enumerate(
                zip(rec_texts, rec_scores, adjusted_polys)
            ):
                if score < 0.5:
                    continue

                # è½¬æ¢ä¸ºæ•´æ•°åæ ‡
                points = np.array(bbox, dtype=np.int32)

                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.polylines(output_image, [points], True, color, 2)

                # è®¡ç®—ä¸­å¿ƒç‚¹
                center_x = int((bbox[0][0] + bbox[2][0]) / 2)
                center_y = int((bbox[0][1] + bbox[2][1]) / 2)

                # ç»˜åˆ¶ä¸­å¿ƒç‚¹
                cv2.circle(output_image, (center_x, center_y), 4, color, -1)

                # å‡†å¤‡æ ‡æ³¨æ–‡æœ¬
                label = f"{text}({center_x},{center_y})"

                # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆåœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹ï¼‰
                text_x = int(bbox[0][0])
                text_y = int(bbox[0][1]) - 8

                # ç¡®ä¿æ–‡æœ¬ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
                if text_y < 15:
                    text_y = int(bbox[2][1]) + 20

                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                (text_w, text_h), _ = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
                )
                cv2.rectangle(
                    output_image,
                    (text_x, text_y - text_h - 2),
                    (text_x + text_w, text_y + 2),
                    color,
                    -1,
                )

                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(
                    output_image,
                    label,
                    (text_x, text_y),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (255, 255, 255),
                    1,
                )

                print(
                    f"      - '{text}' at ({center_x}, {center_y}) [ç½®ä¿¡åº¦: {score:.2f}]"
                )

    # ä¿å­˜è¾“å‡ºå›¾åƒ
    cv2.imwrite(output_path, output_image)
    print(f"\nâœ… æ€»å…±è¯†åˆ«åˆ° {total_texts} ä¸ªæ–‡å­—")
    print(f"âœ… æ ‡æ³¨å›¾åƒå·²ä¿å­˜åˆ°: {output_path}")

    # åŒæ—¶ä¿å­˜ä¸€ä¸ªç¼©æ”¾ç‰ˆæœ¬ï¼ˆæ–¹ä¾¿æŸ¥çœ‹ï¼‰
    scale = 0.5
    small_image = cv2.resize(output_image, None, fx=scale, fy=scale)
    small_output_path = output_path.replace(".png", "_small.png")
    cv2.imwrite(small_output_path, small_image)
    print(f"âœ… ç¼©æ”¾å›¾åƒå·²ä¿å­˜åˆ°: {small_output_path}")


def main():
    """ä¸»å‡½æ•°"""
    image_path = "/tmp/screenshot.png"
    output_path = "/tmp/screenshot_annotated.png"

    print("=" * 60)
    print("OCR åŒºåŸŸå¯è§†åŒ–å·¥å…·")
    print("=" * 60)

    visualize_all_regions(image_path, output_path)

    print("\n" + "=" * 60)
    print("å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
