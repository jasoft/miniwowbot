#!/usr/bin/env python3
"""
æ¸…ç†å’Œé‡ç»„ç¼“å­˜ç›®å½•ç»“æ„
"""

import argparse
import os
import shutil


def cleanup_output_directory(full_clean=False):
    """
    æ¸…ç† output ç›®å½•ï¼Œé‡ç»„ç¼“å­˜ç»“æ„
    
    Args:
        full_clean (bool): æ˜¯å¦æ‰§è¡Œå®Œå…¨æ¸…ç†ï¼ˆåŒ…æ‹¬åˆ é™¤æ•°æ®åº“ï¼‰
    """
    print("=" * 60)
    print("æ¸…ç†å’Œé‡ç»„ç¼“å­˜ç›®å½•ç»“æ„")
    if full_clean:
        print("âš ï¸ è­¦å‘Š: å°†æ‰§è¡Œå®Œå…¨æ¸…ç†ï¼Œåˆ é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®åº“ï¼")
    print("=" * 60)

    output_dir = "output"
    cache_dir = os.path.join(output_dir, "cache")
    temp_dir = os.path.join(output_dir, "temp")
    db_path = os.path.join(cache_dir, "cache.db")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(cache_dir, exist_ok=True)
    os.makedirs(temp_dir, exist_ok=True)
    
    # 0. å¦‚æœæ˜¯å®Œå…¨æ¸…ç†ï¼Œå…ˆåˆ é™¤æ•°æ®åº“
    if full_clean and os.path.exists(db_path):
        try:
            print(f"\nğŸ§¨ æ­£åœ¨åˆ é™¤ç¼“å­˜æ•°æ®åº“: {db_path}")
            os.remove(db_path)
            print("âœ… ç¼“å­˜æ•°æ®åº“å·²åˆ é™¤")
        except Exception as e:
            print(f"âŒ åˆ é™¤æ•°æ®åº“å¤±è´¥: {e}")

    # 1. ç§»åŠ¨æ‰€æœ‰ JSON æ–‡ä»¶åˆ° cache ç›®å½•
    print("\nğŸ“ ç§»åŠ¨ JSON æ–‡ä»¶åˆ° cache ç›®å½•...")
    json_files_moved = 0
    for filename in os.listdir(output_dir):
        if filename.endswith("_res.json") and not filename.startswith("cache_"):
            src = os.path.join(output_dir, filename)
            dst = os.path.join(cache_dir, filename)
            if os.path.exists(src) and not os.path.exists(dst):
                shutil.move(src, dst)
                json_files_moved += 1
                print(f"  ç§»åŠ¨: {filename}")
    print(f"âœ… ç§»åŠ¨äº† {json_files_moved} ä¸ª JSON æ–‡ä»¶")

    # 2. æ¸…ç†æ—§çš„ cache æ–‡ä»¶
    print("\nğŸ—‘ï¸ æ¸…ç†æ—§çš„ç¼“å­˜æ–‡ä»¶...")
    cache_files_removed = 0
    cache_files_failed = 0
    total_size_freed = 0

    # å¦‚æœæ•°æ®åº“è¢«åˆ é™¤äº†ï¼ˆæˆ–è€…ä¸å­˜åœ¨ï¼‰ï¼Œæ‰€æœ‰ç¼“å­˜æ–‡ä»¶éƒ½åº”è¯¥è¢«æ¸…ç†
    if not os.path.exists(db_path):
        print("  æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå°†æ¸…ç†æ‰€æœ‰ç¼“å­˜æ–‡ä»¶...")
        files_to_keep = set()
    else:
        # è¯»å–æ•°æ®åº“ï¼Œäº†è§£å“ªäº›æ–‡ä»¶åº”è¯¥ä¿ç•™
        # æ³¨æ„ï¼šç°åœ¨æ•°æ®åº“åªå­˜å“ˆå¸Œå’ŒJSONï¼Œä¸å­˜æ–‡ä»¶è·¯å¾„ï¼Œæ‰€ä»¥ç†è®ºä¸Š cache ç›®å½•ä¸‹ä¸åº”è¯¥æœ‰å›¾ç‰‡æ–‡ä»¶
        # é™¤éæ˜¯æ—§ç‰ˆæœ¬çš„æ®‹ç•™ã€‚è¿™é‡Œæˆ‘ä»¬ä¿ç•™ cache.db å’Œç´¢å¼•æ–‡ä»¶
        files_to_keep = {"cache.db", "cache_index.json"}

    print("  æ‰«æ cache ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶...")
    all_files = os.listdir(cache_dir)
    print(f"  æ€»æ–‡ä»¶æ•°: {len(all_files)}")

    for filename in all_files:
        filepath = os.path.join(cache_dir, filename)

        # å§‹ç»ˆä¿ç•™æ•°æ®åº“æ–‡ä»¶ï¼ˆå¦‚æœå®ƒè¿˜æ²¡è¢«åˆ ï¼‰
        if filename == "cache.db":
            continue

        # å¦‚æœæ–‡ä»¶ä¸åœ¨ä¿ç•™åˆ—è¡¨ä¸­ï¼Œåˆ é™¤å®ƒ
        if filename not in files_to_keep:
            try:
                if os.path.isfile(filepath):
                    file_size = os.path.getsize(filepath)
                    os.remove(filepath)
                    cache_files_removed += 1
                    total_size_freed += file_size
                elif os.path.isdir(filepath):
                    # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’åˆ é™¤
                    shutil.rmtree(filepath)
                    cache_files_removed += 1
            except Exception as e:
                cache_files_failed += 1
                print(f"  âš ï¸ åˆ é™¤å¤±è´¥: {filename} - {e}")

    print(f"âœ… åˆ é™¤äº† {cache_files_removed} ä¸ªæ–‡ä»¶")
    if cache_files_failed > 0:
        print(f"âš ï¸ åˆ é™¤å¤±è´¥: {cache_files_failed} ä¸ªæ–‡ä»¶")
    if total_size_freed > 0:
        size_mb = total_size_freed / 1024 / 1024
        print(f"ğŸ“Š é‡Šæ”¾ç©ºé—´: {size_mb:.2f} MB")

    # 3. åˆ›å»º temp ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    print("\nğŸ“ ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨...")
    os.makedirs(temp_dir, exist_ok=True)
    
    # æ¸…ç† temp ç›®å½•
    print("ğŸ§¹ æ¸…ç† temp ç›®å½•...")
    temp_removed = 0
    for filename in os.listdir(temp_dir):
        filepath = os.path.join(temp_dir, filename)
        try:
            if os.path.isfile(filepath):
                os.remove(filepath)
                temp_removed += 1
            elif os.path.isdir(filepath):
                shutil.rmtree(filepath)
                temp_removed += 1
        except Exception:
            pass
    print(f"âœ… æ¸…ç†äº† {temp_removed} ä¸ªä¸´æ—¶æ–‡ä»¶")

    # 4. æ˜¾ç¤ºç›®å½•ç»“æ„
    print("\nğŸ“Š æ–°çš„ç›®å½•ç»“æ„:")
    print("output/")
    print("â”œâ”€â”€ cache/        # ç¼“å­˜ç›®å½•ï¼ˆä»…ç¼“å­˜æ•°æ®åº“ï¼‰")
    print("â”œâ”€â”€ temp/         # ä¸´æ—¶æ–‡ä»¶ï¼ˆå·²æ¸…ç©ºï¼‰")

    # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
    cache_files = len(os.listdir(cache_dir)) if os.path.exists(cache_dir) else 0
    temp_files = len(os.listdir(temp_dir)) if os.path.exists(temp_dir) else 0

    print("\nğŸ“ˆ æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  - cache ç›®å½•: {cache_files} ä¸ªæ–‡ä»¶")
    print(f"  - temp ç›®å½•: {temp_files} ä¸ªæ–‡ä»¶")
    print(
        f"  - output æ ¹ç›®å½•: {len([f for f in os.listdir(output_dir) if f not in ['cache', 'temp']])} ä¸ªæ–‡ä»¶"
    )

    print("\nâœ… æ¸…ç†å®Œæˆï¼")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ¸…ç† OCR ç¼“å­˜å·¥å…·")
    parser.add_argument("-f", "--full", action="store_true", help="æ‰§è¡Œå®Œå…¨æ¸…ç†ï¼ˆåˆ é™¤ç¼“å­˜æ•°æ®åº“ï¼‰")
    args = parser.parse_args()

    import logging

    # åˆå§‹åŒ–æ—¥å¿—
    try:
        from logger_config import setup_logger_from_config

        logger = setup_logger_from_config(use_color=True)
    except Exception:
        # å¦‚æœæ— æ³•å¯¼å…¥æ—¥å¿—é…ç½®ï¼Œä½¿ç”¨åŸºç¡€æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)

    try:
        cleanup_output_directory(full_clean=args.full)
    except Exception as e:
        import traceback

        error_traceback = traceback.format_exc()
        logger.critical(
            f"ç¼“å­˜æ¸…ç†å·¥å…·å¼‚å¸¸é€€å‡º: {type(e).__name__}: {str(e)}\n{error_traceback}"
        )
        raise
